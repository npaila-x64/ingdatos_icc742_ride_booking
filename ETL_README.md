# Ride Booking ETL - Medallion Architecture

A production-ready ETL pipeline implementing the **Medallion Architecture** (Bronze â†’ Silver â†’ Gold) for ride booking analytics, orchestrated with **Prefect** and powered by **PostgreSQL**.

## ğŸ“‹ Table of Contents

- [Overview](#overview)
- [Architecture](#architecture)
- [Data Model](#data-model)
- [Quick Start](#quick-start)
- [Usage](#usage)
- [Project Structure](#project-structure)
- [Configuration](#configuration)
- [Development](#development)

## ğŸ¯ Overview

This ETL pipeline processes ride booking data from semi-structured CSV files into a multi-layered analytical data warehouse:

- **Bronze Layer**: Raw data extraction with monthly partitioning
- **Silver Layer**: Normalized dimensional model with fact and dimension tables
- **Gold Layer**: Pre-aggregated analytics for fast querying

### Key Features

âœ… **Medallion Architecture** - Industry-standard data lake pattern  
âœ… **Prefect Orchestration** - Robust workflow management with retries  
âœ… **PostgreSQL Storage** - ACID-compliant relational database  
âœ… **Incremental Processing** - Efficient monthly data partitioning  
âœ… **Idempotent Operations** - Safe to re-run with upsert logic  
âœ… **Type Safety** - Pydantic models and type hints throughout  

## ğŸ—ï¸ Architecture

### Medallion Layers

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Source Data    â”‚
â”‚  (CSV Files)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      Extract & Partition by Month
â”‚  BRONZE LAYER   â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”‚  Raw Staging    â”‚      â€¢ customer
â”‚                 â”‚      â€¢ vehicle_type
â”‚  Partitioned    â”‚      â€¢ location
â”‚  by Month       â”‚      â€¢ booking
â”‚                 â”‚      â€¢ booking_status
â”‚                 â”‚      â€¢ payment_method
â”‚                 â”‚      â€¢ ride
â”‚                 â”‚      â€¢ cancelled_ride
â”‚                 â”‚      â€¢ incompleted_ride
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      Transform to Dimensional Model
â”‚  SILVER LAYER   â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”‚  Normalized     â”‚      Dimensions:
â”‚  Model          â”‚      â€¢ customer
â”‚                 â”‚      â€¢ vehicle_type
â”‚  Star Schema    â”‚      â€¢ location
â”‚                 â”‚      â€¢ booking_status
â”‚                 â”‚      â€¢ payment_method
â”‚                 â”‚
â”‚                 â”‚      Facts:
â”‚                 â”‚      â€¢ booking
â”‚                 â”‚      â€¢ ride
â”‚                 â”‚      â€¢ cancelled_ride
â”‚                 â”‚      â€¢ incompleted_ride
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      Aggregate Analytics
â”‚   GOLD LAYER    â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”‚  Analytics      â”‚      â€¢ daily_booking_summary
â”‚  Ready          â”‚      â€¢ customer_analytics
â”‚                 â”‚      â€¢ location_analytics
â”‚  Aggregated     â”‚
â”‚  Metrics        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Data Flow

1. **Ingestion**: CSV files â†’ Bronze tables (partitioned by `extraction_month`)
2. **Transformation**: Bronze â†’ Silver with deduplication and normalization
3. **Aggregation**: Silver â†’ Gold with pre-computed metrics

## ğŸ“Š Data Model

### Bronze Layer

All Bronze tables include:
- `extraction_date`: Date when data was extracted
- `extraction_month`: Partition key (format: `YYYY-MM`)
- `source_file`: Original CSV filename
- `created_at`: Record insertion timestamp

### Silver Layer

#### Dimension Tables
- `customer` - Customer master data
- `vehicle_type` - Vehicle type lookup
- `location` - Location lookup (pickup/drop)
- `booking_status` - Booking status codes
- `payment_method` - Payment method types

#### Fact Tables
- `booking` - Main booking transactions
  - Foreign keys to all dimension tables
  - Stores: date, time, booking_value
- `ride` - Completed ride metrics
  - Links to booking via `booking_id`
  - Metrics: distance, ratings (driver, customer), TAT values
- `cancelled_ride` - Cancellation records
  - Tracks who cancelled and reason
- `incompleted_ride` - Incomplete ride records
  - Tracks incompletion reasons

### Gold Layer

- `daily_booking_summary` - Daily aggregated metrics
- `customer_analytics` - Customer-level KPIs
- `location_analytics` - Location-level statistics

## ğŸš€ Quick Start

### Prerequisites

- Python 3.10+
- Docker & Docker Compose
- PostgreSQL (via Docker)

### 1. Clone and Setup

```bash
git clone <repository-url>
cd ingdatos_icc742_ride_booking

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -e .
```

### 2. Start Database

```bash
# Start PostgreSQL with Bronze/Silver/Gold schemas
docker-compose up -d postgres

# Wait for database to be ready
docker-compose ps
```

The database will automatically:
- Create schemas: `bronze`, `silver`, `gold`
- Run initialization scripts from `init-db/`
- Set up all required tables

### 3. Run ETL Pipeline

```bash
# Run full ETL pipeline
python -m app.etl.cli run

# Or use the flows directly
python -m app.etl.flows
```

## ğŸ“– Usage

### Command-Line Interface

```bash
# Full ETL with all layers
python -m app.etl.cli run

# Process specific file
python -m app.etl.cli run --source-file data/my_bookings.csv

# Incremental load (new data only)
python -m app.etl.cli incremental --source-file data/2024-10-bookings.csv

# Backfill (reprocess Silver and Gold from existing Bronze)
python -m app.etl.cli backfill

# Skip specific layers
python -m app.etl.cli run --skip-gold
```

### Python API

```python
from app.etl.flows import ride_booking_etl
from datetime import datetime

# Run full pipeline
results = ride_booking_etl(
    source_file="data/ncr_ride_bookings.csv",
    extraction_date=datetime(2024, 10, 21),
    run_bronze=True,
    run_silver=True,
    run_gold=True,
)

print(results)
# {
#   'bronze': {'bronze.customer': 1500, 'bronze.booking': 1500, ...},
#   'silver': {'silver.customer': 800, 'silver.booking': 1500, ...},
#   'gold': {'gold.daily_booking_summary': 30, ...}
# }
```

### Prefect Deployment

```bash
# Deploy flows to Prefect
python -m app.etl.deploy

# Or use Prefect CLI
prefect deployment build app/etl/flows.py:ride_booking_etl -n "production"
prefect deployment apply ride_booking_etl-deployment.yaml
```

## ğŸ“ Project Structure

```
ingdatos_icc742_ride_booking/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ adapters/
â”‚   â”‚   â”œâ”€â”€ postgresql.py        # PostgreSQL adapter with SQLAlchemy
â”‚   â”‚   â””â”€â”€ example_usage.py     # Adapter usage examples
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â””â”€â”€ settings.py          # Configuration management
â”‚   â”œâ”€â”€ etl/
â”‚   â”‚   â”œâ”€â”€ bootstrap.py         # Prefect profile setup
â”‚   â”‚   â”œâ”€â”€ bronze_layer.py      # Bronze extraction tasks
â”‚   â”‚   â”œâ”€â”€ silver_layer.py      # Silver transformation tasks
â”‚   â”‚   â”œâ”€â”€ gold_layer.py        # Gold aggregation tasks
â”‚   â”‚   â”œâ”€â”€ flows.py             # Prefect flow orchestration
â”‚   â”‚   â”œâ”€â”€ deploy.py            # Prefect deployment config
â”‚   â”‚   â””â”€â”€ cli.py               # Command-line interface
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ data/
â”‚   â””â”€â”€ ncr_ride_bookings.csv    # Source data
â”œâ”€â”€ init-db/
â”‚   â”œâ”€â”€ 01_create_schemas.sql    # Schema initialization
â”‚   â””â”€â”€ 02_create_medallion_schema.sql  # Table definitions
â”œâ”€â”€ docker-compose.yml           # Docker orchestration
â”œâ”€â”€ Dockerfile                   # Application container
â”œâ”€â”€ pyproject.toml              # Python dependencies
â”œâ”€â”€ prefect.yaml                # Prefect configuration
â””â”€â”€ README.md                   # This file
```

## âš™ï¸ Configuration

### Environment Variables

Create a `.env` file:

```bash
# Database
DB_HOST=localhost
DB_PORT=5432
DB_NAME=ride_booking
DB_USER=postgres
DB_PASSWORD=postgres
DB_SCHEMA=public

# Prefect
PREFECT_PROFILE=ride-booking-local
PREFECT_API_URL=http://localhost:4200/api

# Project
PROJECT_BASE_PATH=/path/to/project
PROJECT_DATA_DIR=data
```

### Database Settings

Configure via `app/config/settings.py`:

```python
from app.config.settings import load_settings

settings = load_settings()
print(settings.database.connection_string)
```

## ğŸ› ï¸ Development

### Run Tests

```bash
# Install dev dependencies
pip install -e ".[dev]"

# Run tests
pytest

# With coverage
pytest --cov=app
```

### Code Quality

```bash
# Format code
ruff format app/

# Lint
ruff check app/

# Type checking
mypy app/
```

### Database Migrations

The project uses SQL scripts in `init-db/` for schema management. To add new tables:

1. Create a new SQL file: `init-db/03_your_changes.sql`
2. Restart the database: `docker-compose restart postgres`
3. Or apply manually: `psql -U postgres -d ride_booking -f init-db/03_your_changes.sql`

### Viewing Data

```bash
# Connect to database
docker-compose exec postgres psql -U postgres -d ride_booking

# Query Bronze layer
SELECT COUNT(*) FROM bronze.booking;

# Query Silver layer
SELECT bs.name, COUNT(*) 
FROM silver.booking b 
JOIN silver.booking_status bs ON b.booking_status_id = bs.booking_status_id
GROUP BY bs.name;

# Query Gold layer
SELECT * FROM gold.daily_booking_summary ORDER BY summary_date DESC LIMIT 10;
```

### Using pgAdmin

Access pgAdmin at http://localhost:5050 (if running dev profile):

```bash
docker-compose --profile dev up -d pgadmin
```

Credentials:
- Email: `admin@ridebooking.com`
- Password: `admin`

## ğŸ“ Notes

- **Idempotency**: All ETL operations use upsert logic (INSERT ... ON CONFLICT DO UPDATE)
- **Partitioning**: Bronze data is partitioned by `extraction_month` for efficient querying
- **Incremental Loads**: Process only new data by specifying `extraction_month`
- **Data Quality**: Null values are handled appropriately at each layer
- **Performance**: Batch operations are chunked for large datasets

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Run tests and linting
5. Submit a pull request

## ğŸ“„ License

This project is licensed under the MIT License.

---

**Built with** â¤ï¸ **using Prefect, PostgreSQL, and Python**
